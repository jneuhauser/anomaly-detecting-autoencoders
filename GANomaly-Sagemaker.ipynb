{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(python3 train_ganomaly.py \\\n",
    "  \\\n",
    "  --epochs 1 \\\n",
    "  --batch_size 64 \\\n",
    "  --learning_rate 0.0002 \\\n",
    "  \\\n",
    "  --dataset_name mnist \\\n",
    "  --cache_path /tmp \\\n",
    "  --abnormal_class 2 \\\n",
    "  --image_size 32 \\\n",
    "  --image_channels 0 \\\n",
    "  --buffer_size 1000 \\\n",
    "  --shuffle y \\\n",
    "  --prefetch y \\\n",
    "  --random_brightness n \\\n",
    "  --random_crop n \\\n",
    "  --random_flip n \\\n",
    "  --repeat_dataset 0 \\\n",
    "  \\\n",
    "  --latent_size 100 \\\n",
    "  --n_extra_layers 0 \\\n",
    "  --n_filters 64 \\\n",
    "  --w_adv 1 \\\n",
    "  --w_rec 50 \\\n",
    "  --w_enc 1 \\\n",
    "  \\\n",
    "  --train_steps 1 \\\n",
    "  --eval_steps 1 \\\n",
    "  --log_level debug \\\n",
    "  --debug y \\\n",
    "  \\\n",
    "  --data_dir ./trainig/data \\\n",
    "  --model_dir ./trainig/model \\\n",
    "  --output_data_dir ./trainig/output \\\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "import sagemaker\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-thesis-anomaly-detection'\n",
    "\n",
    "artifacts_path = 'ganomaly/testing'\n",
    "artifacts_path_s3 = 's3://{}/training/{}'.format(bucket, artifacts_path)\n",
    "\n",
    "dataset_name = 'currently_unused'\n",
    "dataset_path_s3 = 's3://{}/datasets/{}'.format(bucket, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    # training params\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.0002,\n",
    "\n",
    "    # tf.data piepline params\n",
    "    'dataset_name': 'mnist',\n",
    "    'cache_path': '/tmp/tfdata',\n",
    "    'abnormal_class': 2,  # only valid for mnist, fashion_mnist, cifar10, cifar100 and stl10\n",
    "    'image_size': 32,\n",
    "    'image_channels': 0,  # only valid for MVTec AD\n",
    "    'buffer_size': 1000,\n",
    "    'shuffle': True,\n",
    "    'prefetch': True,\n",
    "    'random_flip': False,\n",
    "    'random_crop': False,\n",
    "    'random_brightness': False,\n",
    "    'repeat_dataset': 0,\n",
    "\n",
    "    # model params\n",
    "    'latent_size': 100,\n",
    "    'n_filters': 64,\n",
    "    'n_extra_layers': 0,\n",
    "    'w_adv': 1,\n",
    "    'w_rec': 50,\n",
    "    'w_enc': 1,\n",
    "\n",
    "    # debugging params\n",
    "    #'train_steps': None,\n",
    "    #'eval_steps': None,\n",
    "    'log_level': 'info',\n",
    "    'debug': False,\n",
    "\n",
    "    # input/output dir params\n",
    "    # they are set through env vars\n",
    "    #'data_dir': './trainig/data',\n",
    "    #'model_dir': './trainig/model',\n",
    "    #'output_data_dir': './trainig/output'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_hyperparameters = hyperparameters.copy()\n",
    "local_hyperparameters['epochs']      = 1\n",
    "#local_hyperparameters['train_steps'] = 1\n",
    "#local_hyperparameters['eval_steps']  = 1\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point = 'train_ganomaly.py',\n",
    "    source_dir = os.getcwd(),\n",
    "    role = sagemaker.get_execution_role(),\n",
    "    framework_version = '2.3.0',\n",
    "    py_version = 'py37',\n",
    "    hyperparameters = local_hyperparameters,\n",
    "    train_instance_count = 1,\n",
    "    train_instance_type = 'local' if subprocess.call('nvidia-smi') != 0 else 'local_gpu',\n",
    "    #code_location = \"file://\" + artifacts_path_local,\n",
    "    #output_path = \"file://\" + artifacts_path_local\n",
    "    code_location = artifacts_path_s3,\n",
    "    output_path = artifacts_path_s3\n",
    ")\n",
    "\n",
    "inputs = {\n",
    "    'data_dir' : dataset_path_s3\n",
    "}\n",
    "\n",
    "estimator.fit(\n",
    "    #inputs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
