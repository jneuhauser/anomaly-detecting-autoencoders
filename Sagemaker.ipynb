{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-thesis-anomaly-detection'\n",
    "\n",
    "artifacts_path = 'ganomaly/testing'\n",
    "artifacts_path_s3 = 's3://{}/training/{}'.format(bucket, artifacts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(python3 train_ganomaly.py \\\n",
    "  \\\n",
    "  --epochs 1 \\\n",
    "  --batch_size 64 \\\n",
    "  --learning_rate 0.0002 \\\n",
    "  --early_stopping 100 \\\n",
    "  \\\n",
    "  --dataset_name mnist \\\n",
    "  --cache_path /tmp \\\n",
    "  --abnormal_class 2 \\\n",
    "  --image_size 32 \\\n",
    "  --image_channels 0 \\\n",
    "  --buffer_size 1000 \\\n",
    "  --shuffle y \\\n",
    "  --prefetch y \\\n",
    "  --random_brightness n \\\n",
    "  --random_crop n \\\n",
    "  --random_flip n \\\n",
    "  --repeat_dataset 0 \\\n",
    "  \\\n",
    "  --model_name ganomaly \\\n",
    "  --latent_size 100 \\\n",
    "  --intermediate_size 100 \\\n",
    "  --n_filters 64 \\\n",
    "  --n_extra_layers 0 \\\n",
    "  --w_adv 1 \\\n",
    "  --w_rec 50 \\\n",
    "  --w_enc 1 \\\n",
    "  \\\n",
    "  --train_steps 1 \\\n",
    "  --eval_steps 1 \\\n",
    "  --log_level debug \\\n",
    "  --debug y \\\n",
    "  \\\n",
    "  --data_dir ./trainig/data \\\n",
    "  --model_dir ./trainig/model \\\n",
    "  --output_data_dir ./trainig/output \\\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "import sagemaker\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    # training params\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.0002,\n",
    "    'early_stopping': 100,\n",
    "\n",
    "    # tf.data piepline params\n",
    "    'dataset_name': 'mnist',\n",
    "    'cache_path': '/tmp/tfdata',\n",
    "    'abnormal_class': 2,  # only valid for mnist, fashion_mnist, cifar10, cifar100 and stl10\n",
    "    'image_size': 32,\n",
    "    'image_channels': 0,  # only valid for MVTec AD\n",
    "    'buffer_size': 1000,\n",
    "    'shuffle': True,\n",
    "    'prefetch': True,\n",
    "    'random_flip': False,\n",
    "    'random_crop': False,\n",
    "    'random_brightness': False,\n",
    "    'repeat_dataset': 0,\n",
    "\n",
    "    # model params\n",
    "    'model_name': 'ganomaly',   # cae, cnae, cvae, ganomaly\n",
    "    'latent_size': 100,\n",
    "    'intermediate_size': 100,   # only valid for cvae\n",
    "    'n_filters': 64,\n",
    "    'n_extra_layers': 0,\n",
    "    'w_adv': 1,                 # only valid for GANomaly\n",
    "    'w_rec': 50,                # only valid for GANomaly\n",
    "    'w_enc': 1,                 # only valid for GANomaly\n",
    "\n",
    "    # debugging params\n",
    "    'train_steps': 0,\n",
    "    'eval_steps': 0,\n",
    "    'log_level': 'info',\n",
    "    'debug': False,\n",
    "\n",
    "    # input/output dir params\n",
    "    # they are set through env vars\n",
    "    #'data_dir': './trainig/data',\n",
    "    #'model_dir': './trainig/model',\n",
    "    #'output_data_dir': './trainig/output'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'auc(roc)', 'Regex': 'Curr Epoch [0-9]+: AUC\\(ROC\\): (.*?),'},\n",
    "    {'Name': 'ptp_loss', 'Regex': 'Curr Epoch [0-9]+: AUC\\(ROC\\): .*?, ptp_loss: (.*?),'},\n",
    "    {'Name': 'min_loss', 'Regex': 'Curr Epoch [0-9]+: AUC\\(ROC\\): .*?, ptp_loss: .*?, min_loss: (.*)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_hyperparameters = hyperparameters.copy()\n",
    "local_hyperparameters['epochs']      = 1\n",
    "local_hyperparameters['train_steps'] = 1\n",
    "local_hyperparameters['eval_steps']  = 1\n",
    "\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "estimator = TensorFlow(\n",
    "    base_job_name='TRAIN-GANomaly-{}-{}-{}-{}'.format(\n",
    "        local_hyperparameters['dataset_name'],\n",
    "        local_hyperparameters['image_size'],\n",
    "        local_hyperparameters['image_channels'],\n",
    "        local_hyperparameters['latent_size']),\n",
    "    entry_point = 'train_ganomaly.py',\n",
    "    source_dir = os.getcwd(),\n",
    "    role = sagemaker.get_execution_role(),\n",
    "    framework_version = '2.3.0',\n",
    "    py_version = 'py37',\n",
    "    hyperparameters = local_hyperparameters,\n",
    "    train_instance_count = 1,\n",
    "    train_instance_type = 'local' if subprocess.call('nvidia-smi') != 0 else 'local_gpu',\n",
    "    #train_max_run = 5 * 24 * 60 * 60 # 5 days\n",
    "    #code_location = \"file://\" + artifacts_path_local,\n",
    "    #output_path = \"file://\" + artifacts_path_local\n",
    "    code_location = artifacts_path_s3,\n",
    "    output_path = artifacts_path_s3,\n",
    "    metric_definitions=metric_definitions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_hyperparameters = hyperparameters.copy()\n",
    "cloud_hyperparameters['epochs']         = 1000\n",
    "cloud_hyperparameters['dataset_name']   = 'bottle'\n",
    "cloud_hyperparameters['image_size']     = 128\n",
    "cloud_hyperparameters['image_channels'] = 3\n",
    "cloud_hyperparameters['random_flip']    = True\n",
    "cloud_hyperparameters['random_crop']    = True\n",
    "cloud_hyperparameters['repeat_dataset'] = 10\n",
    "cloud_hyperparameters['model_name']     = 'cae'\n",
    "cloud_hyperparameters['model_name']     = 'cnae'\n",
    "cloud_hyperparameters['model_name']     = 'cvae'\n",
    "cloud_hyperparameters['model_name']     = 'ganomaly'\n",
    "cloud_hyperparameters['latent_size']    = 900\n",
    "cloud_hyperparameters['intermediate_size'] = 900\n",
    "cloud_hyperparameters['n_filters']      = 32\n",
    "\n",
    "# https://aws.amazon.com/de/sagemaker/pricing/instance-types/\n",
    "# ml.p3.2xlarge (cpus=8, gpus=1xV100, ram=61, gram=16) 3,823 USD pro Stunde\n",
    "# ml.p2.xlarge (cpus=4, gpus=1xK80, ram=61, gram=12) 1,326 USD pro Stunde\n",
    "# ml.g4dn.xlarge (cpus=4, gpus=1xT4, ram=16, gram=16) 0,658 USD pro Stunde\n",
    "# ml.g4dn.2xlarge (cpus=8, gpus=1xT4, ram=32, gram=16) 0,94 USD pro Stunde\n",
    "# ml.g4dn.4xlarge (cpus=16, gpus=1xT4, ram=64, gram=16) 1,505 USD pro Stunde\n",
    "# ml.g4dn.12xlarge (cpus=48, gpus=4xT4, ram=192, gram=64) 4,89 USD pro Stunde\n",
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "estimator = TensorFlow(\n",
    "    base_job_name='TRAIN-AD-{}-{}-{}-{}-{}-{}'.format(\n",
    "        cloud_hyperparameters['model_name'],\n",
    "        cloud_hyperparameters['dataset_name'],\n",
    "        cloud_hyperparameters['image_size'],\n",
    "        cloud_hyperparameters['image_channels'],\n",
    "        cloud_hyperparameters['latent_size'],\n",
    "        cloud_hyperparameters['n_filters']\n",
    "    ),\n",
    "    entry_point = 'train.py',\n",
    "    source_dir = os.getcwd(),\n",
    "    role = sagemaker.get_execution_role(),\n",
    "    framework_version = '2.3.0',\n",
    "    py_version = 'py37',\n",
    "    hyperparameters = cloud_hyperparameters,\n",
    "    train_instance_count = 1,\n",
    "    train_instance_type = instance_type,\n",
    "    #train_max_run = 5 * 24 * 60 * 60 # 5 day on \"ml.g4dn.xlarge\" -> 79,2 USD\n",
    "    #code_location = \"file://\" + artifacts_path_local,\n",
    "    #output_path = \"file://\" + artifacts_path_local\n",
    "    code_location = artifacts_path_s3,\n",
    "    output_path = artifacts_path_s3,\n",
    "    metric_definitions=metric_definitions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    #'batch_size': CategoricalParameter([32, 64, 128, 256]), #IntegerParameter(16, 128),\n",
    "    #'learning_rate': CategoricalParameter([0.0001, 0.0002, 0.0004, 0.0008]), #ContinuousParameter(0.0002, 0.001),\n",
    "    #'image_size': CategoricalParameter([32, 64, 128]),\n",
    "    'latent_size': CategoricalParameter([900, 1200]),\n",
    "    'n_filters': CategoricalParameter([16, 32, 64]),\n",
    "}\n",
    "\n",
    "objective_metric_name = 'auc(roc)'\n",
    "objective_type = 'Maximize' #'Minimize'\n",
    "tuner_metric_definitions = [\n",
    "    {'Name': 'auc(roc)', 'Regex': 'Best Epoch [0-9]+: AUC\\(ROC\\): (.*?),'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    tuner_metric_definitions,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    "    base_tuning_job_name='TUNE-{}-{}'.format(\n",
    "        cloud_hyperparameters['model_name'],\n",
    "        cloud_hyperparameters['dataset_name']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(pip install --upgrade pip)\n",
    "!(pip install --upgrade tensorflow==2.3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from packaging import version\n",
    "assert version.parse('2.3') <= version.parse(tf.version.VERSION), \"Tensorflow 2.3 or geater required\"\n",
    "\n",
    "from datasets.mvtec_ad import get_labeled_dataset\n",
    "from models.cae import CAE\n",
    "from models.cnae import CNAE\n",
    "from models.cvae import CVAE\n",
    "from models.ganomaly import Generator\n",
    "from utils.plot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainings = [\n",
    "    {   # Best Epoch 505: AUC(ROC): 0.97262, ptp_loss: 0.00555, min_loss: 0.00093\n",
    "        'job_name': 'TRAIN-AD-cae-bottle-128-3-900-32-2020-10-27-15-04-51-584',\n",
    "        'model_name': 'cae',\n",
    "        'dataset_name': 'bottle',\n",
    "        'model_args': {\n",
    "            'input_shape': (128, 128, 3),\n",
    "            'latent_size': 900,\n",
    "            'n_filters': 32\n",
    "        }\n",
    "    },\n",
    "    {   # Best Epoch 192: AUC(ROC): 0.96786, ptp_loss: 0.00714, min_loss: 0.00158\n",
    "        'job_name': 'TRAIN-AD-cnae-bottle-128-3-900-32-2020-10-28-13-58-31-220',\n",
    "        'model_name': 'cnae',\n",
    "        'dataset_name': 'bottle',\n",
    "        'model_args': {\n",
    "            'input_shape': (128, 128, 3),\n",
    "            'latent_size': 900,\n",
    "            'n_filters': 32\n",
    "        }\n",
    "    },\n",
    "    {   # Best Epoch 296: AUC(ROC): 0.97460, ptp_loss: 0.00789, min_loss: 0.00094\n",
    "        'job_name': 'TRAIN-AD-cvae-bottle-128-3-300-32-2020-10-28-14-00-26-567',\n",
    "        'model_name': 'cvae',\n",
    "        'dataset_name': 'bottle',\n",
    "        'model_args': {\n",
    "            'input_shape': (128, 128, 3),\n",
    "            'latent_size': 300,\n",
    "            'intermediate_size': 900,\n",
    "            'n_filters': 32\n",
    "        }\n",
    "    },\n",
    "    {   # Best Epoch 199: AUC(ROC): 0.97262, ptp_loss: 0.16334, min_loss: 0.01880\n",
    "        'job_name': 'TRAIN-AD-ganomaly-bottle-128-3-900-32-2020-10-27-15-05-05-426',\n",
    "        'model_name': 'ganomaly',\n",
    "        'dataset_name': 'bottle',\n",
    "        'model_args': {\n",
    "            'input_shape': (128, 128, 3),\n",
    "            'latent_size': 900,\n",
    "            'n_filters': 32\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = trainings[-1]\n",
    "\n",
    "model_switcher = {\n",
    "    'cae': CAE,\n",
    "    'cnae': CNAE,\n",
    "    'cvae': CVAE,\n",
    "    'ganomaly': Generator\n",
    "}\n",
    "\n",
    "model = model_switcher[training['model_name']](**training['model_args'])\n",
    "\n",
    "model.build((None, *training['model_args']['input_shape']))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = '' # empty means all\n",
    "job_name = training['job_name']\n",
    "!(aws s3 cp {artifacts_path_s3}/{job_name} /tmp/ganomaly/{job_name} --recursive --exclude \"*\" --include \"*/model.tar.gz\")\n",
    "!(for f in $(find /tmp/ganomaly -iname model.tar.gz); do echo \"Extracting ${f}\"; tar xf ${f} -C ${f%/*}; rm ${f}; done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/tmp/ganomaly/{}/output/{}'.format(\n",
    "    training['job_name'],\n",
    "    'generator' if training['model_name'] == 'ganomaly' else ''\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_image = lambda image, label: (tf.image.resize(image, training['model_args']['input_shape'][:2]), label)\n",
    "\n",
    "test_ds = get_labeled_dataset(\n",
    "    category=training['dataset_name'],\n",
    "    split = 'test',\n",
    "    image_channels=training['model_args']['input_shape'][-1],\n",
    "    binary_labels=True\n",
    ")\n",
    "test_ds = test_ds.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.cache('/tmp/tfdata_test_ds_{}_{}_{}.cache'.format(\n",
    "    training['dataset_name'],\n",
    "    training['model_args']['input_shape'][0],\n",
    "    training['model_args']['input_shape'][-1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    x=test_ds.batch(64)\n",
    ")\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(predictions)\n",
    "ptp_val = np.ptp(predictions)\n",
    "print(\"ptp_val:\", ptp_val, \"min_val:\", min_val)\n",
    "\n",
    "predictions -= min_val\n",
    "predictions /= ptp_val\n",
    "\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "n = []\n",
    "for (i, l), p in zip(test_ds, predictions):\n",
    "    if l == 1:\n",
    "        a.append(p)\n",
    "    else:\n",
    "        n.append(p)\n",
    "a = np.array(a)\n",
    "n = np.array(n)\n",
    "print('anomaly: {}; normal: {};'.format(a.shape, n.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "step_size = 1.0 / n_bins\n",
    "bins = np.arange(0.0, 1.0+step_size, step_size)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(a, bins=bins, alpha=0.5, label=\"anomaly\")\n",
    "plt.hist(n, bins=bins, alpha=0.5, label=\"normal\")\n",
    "plt.xlabel(\"Error\", size=14)\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.title(\"Anomaly Detection Histogram\", size=14)\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"ganomaly_bottle_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, l), p in zip(test_ds, predictions):\n",
    "    imshow(i, \"label: {}, pred: {}\".format(\"good\" if l == 0 else \"broken\", p), greyscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
