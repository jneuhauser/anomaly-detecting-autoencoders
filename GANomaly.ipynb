{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training\n",
    "Paper: https://arxiv.org/abs/1805.06725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import models.ganomaly as mg\n",
    "import datasets.common as cds\n",
    "import datasets.mvtec_ad as mvds\n",
    "import utils.datasets as dsu\n",
    "import utils.plot as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in (mg, cds, dsu, pu):\n",
    "    reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = dsu.create_anomaly_dataset(\n",
    "    cds.get_dataset_mnist(),\n",
    "    abnormal_class=2\n",
    ")\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "#print(train_labels[:10])\n",
    "#print(test_labels[5395:5405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_images.shape[1] > 64:\n",
    "    train_images = tf.image.resize(train_images, (64,64))\n",
    "    test_images = tf.image.resize(test_images, (64,64))\n",
    "elif train_images.shape[1] not in [2**x for x in range(10)]:\n",
    "    power = 1\n",
    "    while power < train_images.shape[1]:\n",
    "        power *= 2\n",
    "    new_size = (power, power)\n",
    "    print(\"resizing to:\", new_size)\n",
    "    train_images = tf.image.resize(train_images, new_size)\n",
    "    test_images = tf.image.resize(test_images, new_size)\n",
    "train_labels = train_labels.reshape((-1,1))\n",
    "test_labels = test_labels.reshape((-1,1))\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_start = dsu.find_abnormal_start_index(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.plot_images(test_images[abnormal_start-5:abnormal_start+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mg)\n",
    "model = mg.GANomaly(\n",
    "    input_shape=train_images[0].shape,\n",
    "    latent_size=100\n",
    ")\n",
    "model.compile(metrics=[tf.keras.metrics.AUC()])\n",
    "model.build((None, *train_images[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(mg)\n",
    "adcb = mg.ADModelEvaluator(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)\n",
    "results = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_labels,\n",
    "    batch_size=256,\n",
    "    epochs=15,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    validation_batch_size=test_labels.shape[0]//10,\n",
    "    callbacks=[adcb],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(adcb.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.history.keys())\n",
    "\n",
    "plt.plot(results.history['loss_gen'])\n",
    "plt.title('generator loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['generator'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(results.history['loss_gen_adv'])\n",
    "plt.plot(results.history['loss_gen_rec'])\n",
    "plt.plot(results.history['loss_gen_enc'])\n",
    "plt.title('generator specific losses')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['adversarial', 'reconstruction', 'encoder'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(results.history['loss_dis'])\n",
    "plt.plot(results.history['loss_dis_real'])\n",
    "plt.plot(results.history['loss_dis_fake'])\n",
    "plt.title('discriminator losses')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['real/fake', 'real', 'fake'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# makes no sense as this is only the mse between latent_i and latent_o\n",
    "tf.config.run_functions_eagerly(True)\n",
    "eval_results = model.evaluate(\n",
    "    x=test_images,\n",
    "    y=test_labels,\n",
    "    batch_size=test_images.shape[0]//10,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    x=test_images,\n",
    "    batch_size=test_images.shape[0]//10\n",
    ")\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(predictions)\n",
    "ptp_val = np.ptp(predictions)\n",
    "print(\"ptp_val:\", ptp_val, \"min_val:\", min_val)\n",
    "\n",
    "predictions -= min_val\n",
    "predictions /= ptp_val\n",
    "\n",
    "print(predictions[abnormal_start-15:abnormal_start+15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[abnormal_start-5:abnormal_start+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_normal = model.predict(\n",
    "    x=test_images[:abnormal_start],\n",
    "    batch_size=test_images[:abnormal_start].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max:\", np.max(predictions_normal))\n",
    "print(\"min:\", np.min(predictions_normal))\n",
    "print(\"mean:\", np.mean(predictions_normal))\n",
    "print(\"q(50):\", np.percentile(predictions_normal, 50))\n",
    "print(\"q(75):\", np.percentile(predictions_normal, 75))\n",
    "print(\"q(90):\", np.percentile(predictions_normal, 90))\n",
    "print(\"q(95):\", np.percentile(predictions_normal, 95))\n",
    "print(\"q(99):\", np.percentile(predictions_normal, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_abnormal = model.predict(\n",
    "    x=test_images[abnormal_start:],\n",
    "    batch_size=test_images[abnormal_start:].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max:\", np.max(predictions_abnormal))\n",
    "print(\"min:\", np.min(predictions_abnormal))\n",
    "print(\"mean:\", np.mean(predictions_abnormal))\n",
    "print(\"q(50):\", np.percentile(predictions_abnormal, 50))\n",
    "print(\"q(75):\", np.percentile(predictions_abnormal, 75))\n",
    "print(\"q(90):\", np.percentile(predictions_abnormal, 90))\n",
    "print(\"q(95):\", np.percentile(predictions_abnormal, 95))\n",
    "print(\"q(99):\", np.percentile(predictions_abnormal, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(reconstructed, latent_i, latent_o), (classifier, features) = model(test_images[abnormal_start-5:abnormal_start+5], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_tuples = list(zip(\n",
    "    test_images[abnormal_start-5:abnormal_start+5],\n",
    "    reconstructed\n",
    "))\n",
    "p.plot_image_tuples(image_tuples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
